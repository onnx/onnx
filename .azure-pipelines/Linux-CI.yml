trigger:
- main

jobs:
- job: 'Test'
  pool:
    vmImage: 'Ubuntu-20.04'
  strategy:
    matrix:
      py311-ml-debug:
        python.version: '3.11'
        onnx_ml: 1
        build_type: 'Debug'
        documentation: 0
        protobuf_type: 'External'
      py310-InternalProtobuf:
        python.version: '3.10'
        onnx_ml: 0
        build_type: 'Release'
        documentation: 0
        protobuf_type: 'Internal'
      py39-ml:
        python.version: '3.9'
        onnx_ml: 1
        build_type: 'Release'
        documentation: 1
        protobuf_type: 'External'
      py38-InternalProtobuf:
        python.version: '3.8'
        onnx_ml: 0
        build_type: 'Release'
        documentation: 0
        protobuf_type: 'Internal'
      py38-ml:
        python.version: '3.8'
        onnx_ml: 1
        build_type: 'Release'
        documentation: 0
        protobuf_type: 'External'
    maxParallel: 6

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '$(python.version)'
      addToPath: true

  - script: |
      python -m pip -q install virtualenv
      python -m virtualenv venv
      source venv/bin/activate

      if [ '$(protobuf_type)' == 'External' ]; then
        sudo apt-get install libprotobuf-dev protobuf-compiler
      elif [ '$(protobuf_type)' == 'Internal' ]; then
        echo "Use the internal protobuf build"
      fi

      python -m pip install --upgrade pip
      python -m pip install -r requirements-release.txt
      # still test protobuf==3.20.2 at least in a CI
      python -m pip install protobuf==3.20.2

      sudo apt-get install -qq -o=Dpkg::Use-Pty=0 -y --no-install-recommends dos2unix

      git submodule update --init --recursive
      export ONNX_BUILD_TESTS=1
      if [ '$(build_type)' == 'Debug' ]; then
        export DEBUG=1
      fi
      if [ '$(onnx_ml)' == '1' ]; then
        export ONNX_ML=1
      fi
      export CMAKE_ARGS="-DONNX_WERROR=ON -DONNX_USE_PROTOBUF_SHARED_LIBS=ON"
      # enable more sanitizer
      export CMAKE_ARGS="${CMAKE_ARGS} -DCMAKE_CXX_FLAGS='-fsanitize=undefined -fno-sanitize-recover=all '"
      pip install -e . -v
    displayName: 'Install ONNX and dependencies'

  - script: |
      source venv/bin/activate

      pytest -sv
      if [ $? -ne 0 ]; then
        echo "pytest failed"
        exit 1
      fi

      python -m pip install -r requirements-dev.txt

      # check auto-gen files up-to-date
      python onnx/defs/gen_doc.py
      python onnx/gen_proto.py -l
      python onnx/gen_proto.py -l --ml
      python onnx/backend/test/stat_coverage.py

      git status
      git diff --exit-code -- . ':(exclude)onnx/onnx-data.proto' ':(exclude)onnx/onnx-data.proto3'
      if [ $? -ne 0 ]; then
        echo "git diff returned failures"
        exit 1
      fi

      # Do not hardcode onnx's namespace in the c++ source code, so that
      # other libraries who statically link with onnx can hide onnx symbols
      # in a private namespace.
      ! grep -R --include='*.cc' --include='*.h' 'namespace onnx' .
      ! grep -R --include='*.cc' --include='*.h' 'onnx::' .

      # onnx c++ API tests
      export LD_LIBRARY_PATH="./.setuptools-cmake-build/:$LD_LIBRARY_PATH"
      ./.setuptools-cmake-build/onnx_gtests
      if [ $? -ne 0 ]; then
        echo "onnx_gtests failed"
        exit 1
      fi

    displayName: 'Run ONNX tests'

  - script: |
      source venv/bin/activate
      python onnx/backend/test/cmd_tools.py generate-data --clean
      git status
      # Skip *output_*.pb because NumPy functions might behave differently on different platforms
      # Skip test_log's input.pb because it uses np.random, which might behave differently on different platforms
      git diff --exit-code -- . ':!onnx/onnx-data.proto' ':!onnx/onnx-data.proto3' ':!*output_*.pb' ':!*input_*.pb'
      if [ $? -ne 0 ]; then
        echo "git diff for test generation returned failures. Please check updated node test files"
        exit 1
      fi
      git diff --exit-code --diff-filter=ADR -- . ':!onnx/onnx-data.proto' ':!onnx/onnx-data.proto3'
      if [ $? -ne 0 ]; then
        echo "Test generation returned failures. Please check the number of node test files (input_*.pb or output_*.pb)"
        exit 1
      fi

    displayName: Test backend test data

  - script: |
      if [ '$(documentation)' == '1' ]; then
        source venv/bin/activate
        pip install -r docs/docsgen/source/requirements.txt
        cd docs/docsgen && make text
      fi
    displayName: Test documentation
    continueOnError: true  # the documentation generates errors due to operators documentation
